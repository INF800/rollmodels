{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras2onnx.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOa8G89+vrNEVh6Ki+iF3YP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakesh4real/rollmodels/blob/main/keras2onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67bo14f6L4XC"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reERZLldLrnQ",
        "outputId": "2357fe35-55aa-4104-e4d0-f77bf335ebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# original source: https://github.com/onnx/keras-onnx/tree/master/tutorial\n",
        "# Note: this code is compact and better compared to original\n",
        "\n",
        "\"\"\"\n",
        "## 1. Setup\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "\"\"\"\n",
        "# 2. Random Image\n",
        "\"\"\"\n",
        "def get_and_plot_random_image_from(x_test, y_test):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # get a random image index from the test set\n",
        "    image_index = int(np.random.randint(0, x_test.shape[0], size=1)[0])\n",
        "    expected_label = y_test[image_index]\n",
        "    digit_image = x_test[image_index]\n",
        "    # and plot it\n",
        "    plt.title(f'Example {image_index} Label: {expected_label}')\n",
        "    plt.imshow(digit_image.squeeze(2), cmap='Greys')\n",
        "    plt.show()\n",
        "    return digit_image, image_index\n",
        "\n",
        "\"\"\"\n",
        "# 3. Inference w/o onnx\n",
        "\"\"\"\n",
        "def infer_w_raw_h5(digit_image, expected_label, model, input_shape, loop_count=40):\n",
        "    # reshape the image for inference/prediction\n",
        "    digit_image = digit_image.reshape(1, input_shape[0], input_shape[1], 1)\n",
        "\n",
        "    # loop `loop_count` times\n",
        "    start_time = time.time()\n",
        "    for i in range(loop_count):\n",
        "        prediction_probabs = model.predict(digit_image)\n",
        "    avg_time = ((time.time() - start_time) / loop_count)\n",
        "    print(f\"Keras inferences with {avg_time} second in average\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Prediction probabilities:\")\n",
        "    print(prediction_probabs)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    predicted_label = prediction_probabs.argmax()\n",
        "    print('Predicted value:', predicted_label)\n",
        "\n",
        "    is_correct_pred = None\n",
        "    if (expected_label.argmax() == predicted_label):\n",
        "      print('Correct prediction')\n",
        "      is_correct_pred = True\n",
        "    else:\n",
        "      print('Wrong prediction')\n",
        "      is_correct_pred = False\n",
        "\n",
        "    # can be used for more control (see suggestio where used)\n",
        "    return (is_correct_pred, prediction_probabs), avg_time\n",
        "\n",
        "\"\"\"\n",
        "# 4. Inference w/ onnx\n",
        "\n",
        "!pip install --quiet -U onnxruntime\n",
        "!pip install --quiet -U git+https://github.com/microsoft/onnxconverter-common\n",
        "!pip install --quiet -U git+https://github.com/onnx/keras-onnx\n",
        "\"\"\"\n",
        "!pip install --quiet -U onnxruntime\n",
        "!pip install --quiet -U git+https://github.com/microsoft/onnxconverter-common\n",
        "!pip install --quiet -U git+https://github.com/onnx/keras-onnx\n",
        "\n",
        "import onnxruntime\n",
        "import keras2onnx\n",
        "\n",
        "def h52onnx(model, output_onnxmodel_path='./onnx_model.onnx'):\n",
        "  print(\"keras2onnx version is \"+keras2onnx.__version__)\n",
        "  save_name = output_onnxmodel_path.split(\".onnx\")[0].split(\"/\")[-1] # get name from path\n",
        "  print(save_name)\n",
        "  # convert to onnx model\n",
        "  onnx_model = keras2onnx.convert_keras(model, save_name, debug_mode=1)\n",
        "  # and save the model in ONNX format\n",
        "  keras2onnx.save_model(onnx_model, output_onnxmodel_path)\n",
        "\n",
        "\n",
        "def generate_data_feed_and_sess(digit_image, input_shape, output_onnxmodel_path):\n",
        "    # reshape the image for inference/prediction\n",
        "    digit_image = digit_image.reshape(1, input_shape[0], input_shape[1], 1)\n",
        "    \n",
        "    # define session (include options using docs if necessary)\n",
        "    sess_options = onnxruntime.SessionOptions()\n",
        "    sess = onnxruntime.InferenceSession(output_onnxmodel_path, sess_options)\n",
        "    # define data\n",
        "    data = [digit_image.astype(np.float32)]\n",
        "    # feed data\n",
        "    input_names = sess.get_inputs()\n",
        "    feed = dict([(input.name, data[n]) for n, input in enumerate(sess.get_inputs())])\n",
        "    return feed, sess\n",
        "    \n",
        "\n",
        "def infer_w_onnx_runtime(digit_image, expected_label,\n",
        "                         input_shape,\n",
        "                         output_onnxmodel_path='./onnx_model.onnx',\n",
        "                         loop_count=40):\n",
        "  # setup\n",
        "  feed, sess = generate_data_feed_and_sess(digit_image, input_shape, output_onnxmodel_path)\n",
        "\n",
        "  # calculate average\n",
        "  start_time = time.time()\n",
        "  for i in range(loop_count):\n",
        "      # note: session is used to make preds\n",
        "      onnx_prediction_probabs = sess.run(None, feed)[0]\n",
        "  avg_time = ((time.time() - start_time) / loop_count)\n",
        "  print(f\"ONNX inferences with {avg_time} second in average\")\n",
        "\n",
        "  # compare w/ raw h5\n",
        "  print(\"=\"*60)\n",
        "  print(\"[onnx]Prediction probabilities:\")\n",
        "  print(onnx_prediction_probabs)\n",
        "  print(\"=\"*60)\n",
        "\n",
        "  is_correct_pred = None\n",
        "  print('ONNX predicted value:', onnx_prediction_probabs.argmax())\n",
        "  if (expected_label.argmax() == onnx_prediction_probabs.argmax()):\n",
        "    print('Correct prediction')\n",
        "    is_correct_pred = True\n",
        "  else:\n",
        "    print('Wrong prediction')\n",
        "    is_correct_pred = False\n",
        "\n",
        "  return (is_correct_pred, onnx_prediction_probabs), avg_time"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for onnxconverter-common (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras2onnx (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQoS0fs-qoCa"
      },
      "source": [
        "# **Part 1:** Lighter Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiVPGdNYCVRl"
      },
      "source": [
        "# Create Keras .h5 Model\n",
        "\n",
        "- Makes sure input dims is given in first layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd80L3VIgmBw"
      },
      "source": [
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Important while creating keras model, making inference w and w/o keras (onnx)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26E1zR2P_cUX",
        "outputId": "1ca7de2a-9e43-44bc-c1d6-0cfb631255ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "\"\"\"\n",
        "## Setup\n",
        "\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow\n",
        "print(\"TensorFlow version is \"+tensorflow.__version__)\n",
        "\n",
        "\"\"\"\n",
        "## Prepare the data\n",
        "\"\"\"\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\"\"\"\n",
        "## Build the model\n",
        "\"\"\"\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape), # !NOTE: input shape must be defined @beg to avoid onnx errors\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\"\"\"\n",
        "## Train the model\n",
        "\"\"\"\n",
        "\n",
        "os.makedirs(\"keras_saved_model\", exist_ok=True)\n",
        "checkpoint_filepath = 'keras_saved_model/model.h5'\n",
        "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False, # else, error\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[model_checkpoint_callback])\n",
        "\n",
        "\"\"\"\n",
        "## Evaluate the trained model\n",
        "\"\"\"\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version is 2.3.0\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3589 - accuracy: 0.8914 - val_loss: 0.0826 - val_accuracy: 0.9782\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.0562 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9743 - val_loss: 0.0492 - val_accuracy: 0.9873\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0685 - accuracy: 0.9791 - val_loss: 0.0437 - val_accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0392 - val_accuracy: 0.9903\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0561 - accuracy: 0.9826 - val_loss: 0.0341 - val_accuracy: 0.9902\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.0366 - val_accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0337 - val_accuracy: 0.9907\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0325 - val_accuracy: 0.9913\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.0344 - val_accuracy: 0.9903\n",
            "Test loss: 0.02820633165538311\n",
            "Test accuracy: 0.9902999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwfkAOeEDfr_"
      },
      "source": [
        "# Load and eval best.h5 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXOnOTUQDJwr",
        "outputId": "90e1c5a9-2024-4bc7-c5b3-9ae463fdd18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# best models\n",
        "model = tensorflow.keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "# eval\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.027926113456487656\n",
            "Test accuracy: 0.9909999966621399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8gXaGUhHZ3a",
        "outputId": "04cabb1b-d06a-47c2-f504-8572a861a7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# a. get random image\n",
        "digit_image, digit_idx = get_and_plot_random_image_from(x_test, y_test)\n",
        "\n",
        "# b. loop inference for avg. inference time\n",
        "(_, keras_prbs_40it), keras_time_40it = infer_w_raw_h5(digit_image, expected_label=y_test[digit_idx],\n",
        "                                                              model=model, input_shape=input_shape)\n",
        "\n",
        "# SUGGESTION: For more control, as this is for single, image, \n",
        "# Go one step further by putiing the above two functions \n",
        "# in loop as well and take average"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Keras inferences with 0.028473585844039917 second in average\n",
            "============================================================\n",
            "Prediction probabilities:\n",
            "[[7.0172845e-09 2.2854542e-10 3.4750568e-07 1.1292542e-06 4.7465271e-10\n",
            "  1.1021613e-06 1.5790658e-09 1.8508253e-09 9.9990594e-01 9.1470465e-05]]\n",
            "============================================================\n",
            "Predicted value: 8\n",
            "Correct prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI36w9_PJaqP"
      },
      "source": [
        "# Conversion from Keras to ONNX\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pJG8tvOJeE2",
        "outputId": "5abec415-e988-4c19-a698-2ed4c997dc3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "h52onnx(model, \"./keras-mnist-optimized.onnx\") # saves in curdir"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf executing eager_mode: True\n",
            "tf.keras model eager_mode: False\n",
            "Processing a keras layer - (dense_1: <class 'tensorflow.python.keras.layers.core.Dense'>)\n",
            "\toutput: dense_1/Softmax_1:0\n",
            "\tinput : dropout_1/cond_1/Identity:0\n",
            "Processing a keras layer - (dropout_1: <class 'tensorflow.python.keras.layers.core.Dropout'>)\n",
            "\toutput: dropout_1/cond_1/Identity:0\n",
            "\tinput : flatten_1/Reshape_1:0\n",
            "Processing a keras layer - (flatten_1: <class 'tensorflow.python.keras.layers.core.Flatten'>)\n",
            "\toutput: flatten_1/Reshape_1:0\n",
            "\tinput : max_pooling2d_3/MaxPool_1:0\n",
            "Processing a keras layer - (max_pooling2d_3: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
            "\toutput: max_pooling2d_3/MaxPool_1:0\n",
            "\tinput : conv2d_3/Relu_1:0\n",
            "Processing a keras layer - (conv2d_3: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
            "\toutput: conv2d_3/Relu_1:0\n",
            "\tinput : max_pooling2d_2/MaxPool_1:0\n",
            "Processing a keras layer - (max_pooling2d_2: <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>)\n",
            "\toutput: max_pooling2d_2/MaxPool_1:0\n",
            "\tinput : conv2d_2/Relu_1:0\n",
            "Processing a keras layer - (conv2d_2: <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>)\n",
            "\toutput: conv2d_2/Relu_1:0\n",
            "\tinput : input_2_1:0\n",
            "var: input_2\n",
            "var: input_2_1:0\n",
            "var: input_2_1:01\n",
            "var: conv2d_2/Relu_1:0\n",
            "var: max_pooling2d_2/MaxPool_1:0\n",
            "var: conv2d_3/Relu_1:0\n",
            "var: max_pooling2d_3/MaxPool_1:0\n",
            "var: flatten_1/Reshape_1:0\n",
            "var: dropout_1/cond_1/Identity:0\n",
            "var: dense_1/Softmax_1:01\n",
            "var: dense_1/Softmax_1:0\n",
            "var: dense_1\n",
            "Converting the operator (Identity): Identity\n",
            "Converting the operator (Identity1): Identity\n",
            "Converting the operator (Identity2): Identity\n",
            "Converting the operator (dense_1): <class 'tensorflow.python.keras.layers.core.Dense'>\n",
            "Converting the operator (dropout_1): <class 'tensorflow.python.keras.layers.core.Dropout'>\n",
            "Converting the operator (keras_learning_phase/input): Const\n",
            "Converting the operator (flatten_1): <class 'tensorflow.python.keras.layers.core.Flatten'>\n",
            "Converting the operator (flatten_1/Const_1): Const\n",
            "Converting the operator (max_pooling2d_3): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
            "Converting the operator (conv2d_3): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
            "Converting the operator (max_pooling2d_2): <class 'tensorflow.python.keras.layers.pooling.MaxPooling2D'>\n",
            "Converting the operator (conv2d_2): <class 'tensorflow.python.keras.layers.convolutional.Conv2D'>\n",
            "Converting the operator (Identity3): Identity\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "keras2onnx version is 1.7.1\n",
            "keras-mnist-optimized\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UkDSbKJxIJ"
      },
      "source": [
        "# Evaluate the ONNX's Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOgM8jEvjY02",
        "outputId": "79923645-8405-410c-9203-d42895b06ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "(_, onnxs_prbs_40it), onnx_time_40it = infer_w_onnx_runtime(digit_image, expected_label=y_test[digit_idx], \n",
        "                                                              input_shape=input_shape,\n",
        "                                                              output_onnxmodel_path='./keras-mnist-optimized.onnx') # same path as used above to load"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONNX inferences with 0.00020682215690612794 second in average\n",
            "============================================================\n",
            "[onnx]Prediction probabilities:\n",
            "[[7.0172850e-09 2.2854546e-10 3.4750539e-07 1.1292522e-06 4.7465093e-10\n",
            "  1.1021592e-06 1.5790661e-09 1.8508221e-09 9.9990606e-01 9.1470742e-05]]\n",
            "============================================================\n",
            "ONNX predicted value: 8\n",
            "Correct prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y47Ac50ys2eN"
      },
      "source": [
        "# Comaprision of inference time and model size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msJMtblfs74C",
        "outputId": "51e92ece-e579-4d4d-e589-93af19815c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "plt.figure(figsize=(5, 10))\n",
        "sns.color_palette(\"husl\", 8)\n",
        "sns.barplot(\n",
        "    [\"raw keras\", \"onnx\"],\n",
        "    [keras_time_40it, onnx_time_40it],\n",
        ")\n",
        "\n",
        "plt.title(f\"ratio: {keras_time_40it/onnx_time_40it}\")\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onzQ8cGoyQL6",
        "outputId": "b460e2b0-df5e-4a63-e91b-a5bdd6d6ace1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "digit_labels = list(range(10))\n",
        "\n",
        "df = pd.DataFrame({\n",
        "      'ground_truths': digit_labels\n",
        "})\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=\"time\", hue=\"kind\", y=\"data\", data=df)\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLQ-XaltqxQx"
      },
      "source": [
        "# **Part 2:** Let's Get Heavy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k80PJtfSrK9L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}