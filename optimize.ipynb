{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPR6ntHBRWPU03BMcMd//Ry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakesh4real/role-models/blob/main/optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G-uSF0VTSyr"
      },
      "source": [
        "- **Tool:** [TF Graph Transforms Python API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms)\n",
        "- **Input:** `SavedModel` [format](https://www.tensorflow.org/guide/saved_model) combines a `GraphDef` with checkpoint files that store weights, **all collected in a folder**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytx5Tp81VOoM"
      },
      "source": [
        "# Steps\n",
        "\n",
        "1. Freeze the `SavedModel` model by converting to `Graphdef` format\n",
        "2. Optimize frozen `GraphDef` mode;\n",
        "3. Unfreeze to `SavedModel` format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL8A0KKVucOQ"
      },
      "source": [
        "# Setting up environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDm-Axo-X4f9",
        "outputId": "c1790961-3704-4dad-c402-4cc401128c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install tree\n",
        "!pip install tensorflow==1.15.0 # currently v2 is not supported https://github.com/tensorflow/tensorflow/issues/30746. Temp fix - use 1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"{'='*60}\\nCurrently using {tf.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (145 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 144617 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.1MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=0826bb66a9b5f364392bb01277a3caa99a897d01b6107d09571c6e330ab2f9f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "============================================================\n",
            "Currently using 1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfFOTxy7XJvL"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import data\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python import ops\n",
        "\n",
        "from tensorflow.tools.graph_transforms import TransformGraph # currently, not avl. in v2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWv3P4lLVolT"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "MODELS_LOCATION = 'models/mnist'\n",
        "MODEL_NAME = 'keras_classifier'\n",
        "\n",
        "def load_mnist_keras():\n",
        "  (train_data, train_labels), (eval_data, eval_labels) = tf.keras.datasets.mnist.load_data()\n",
        "  return train_data, train_labels, eval_data, eval_labels\n",
        "\n",
        "def keras_model_fn(params):\n",
        "    \n",
        "  inputs = tf.keras.layers.Input(shape=(28, 28), name='input_image')\n",
        "  input_layer = tf.keras.layers.Reshape(target_shape=(28, 28, 1), name='reshape')(inputs)\n",
        "  \n",
        "  # convolutional layers\n",
        "  conv_inputs = input_layer\n",
        "  for i in range(params.num_conv_layers):      \n",
        "    filters = params.init_filters * (2**i)\n",
        "    conv = tf.keras.layers.Conv2D(kernel_size=3, filters=filters, strides=1, padding='SAME', activation='relu')(conv_inputs)\n",
        "    max_pool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='SAME')(conv)\n",
        "    batch_norm = tf.keras.layers.BatchNormalization()(max_pool)\n",
        "    conv_inputs = batch_norm\n",
        "\n",
        "  flatten = tf.keras.layers.Flatten(name='flatten')(conv_inputs)\n",
        "  \n",
        "  # fully-connected layers\n",
        "  dense_inputs = flatten\n",
        "  for i in range(len(params.hidden_units)):      \n",
        "    dense = tf.keras.layers.Dense(units=params.hidden_units[i], activation='relu')(dense_inputs)\n",
        "    dropout = tf.keras.layers.Dropout(params.dropout)(dense)\n",
        "    dense_inputs = dropout\n",
        "      \n",
        "  # softmax classifier\n",
        "  logits = tf.keras.layers.Dense(units=NUM_CLASSES, name='logits')(dense_inputs)\n",
        "  softmax = tf.keras.layers.Activation('softmax', name='softmax')(logits)\n",
        "\n",
        "  # keras model\n",
        "  model = tf.keras.models.Model(inputs, softmax)\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_estimator_keras(params, run_config):\n",
        "    \n",
        "  keras_model = keras_model_fn(params)\n",
        "  print(keras_model.summary())\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.Adam(lr=params.learning_rate)\n",
        "  keras_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  mnist_classifier = tf.keras.estimator.model_to_estimator(\n",
        "      keras_model=keras_model,\n",
        "      config=run_config\n",
        "  )\n",
        "  \n",
        "  return mnist_classifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgLwArQUWQUo"
      },
      "source": [
        "def run_experiment(hparams, train_data, train_labels, run_config, create_estimator_fn=create_estimator_keras):\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "      input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "          x={'input_image': train_data},\n",
        "          y=train_labels,\n",
        "          batch_size=hparams.batch_size,\n",
        "          num_epochs=None,\n",
        "          shuffle=True),\n",
        "      max_steps=hparams.max_training_steps\n",
        "  )\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "          x={'input_image': train_data},\n",
        "          y=train_labels,\n",
        "          batch_size=hparams.batch_size,\n",
        "          num_epochs=1,\n",
        "          shuffle=False),\n",
        "      steps=None,\n",
        "      throttle_secs=hparams.eval_throttle_secs\n",
        "  )\n",
        "\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  time_start = datetime.utcnow()\n",
        "  print('Experiment started at {}'.format(time_start.strftime('%H:%M:%S')))\n",
        "  print('.......................................')\n",
        "\n",
        "  estimator = create_estimator_fn(hparams, run_config)\n",
        "\n",
        "  tf.estimator.train_and_evaluate(\n",
        "      estimator=estimator,\n",
        "      train_spec=train_spec,\n",
        "      eval_spec=eval_spec\n",
        "  )\n",
        "\n",
        "  time_end = datetime.utcnow()\n",
        "  print('.......................................')\n",
        "  print('Experiment finished at {}'.format(time_end.strftime('%H:%M:%S')))\n",
        "  print('')\n",
        "  time_elapsed = time_end - time_start\n",
        "  print('Experiment elapsed time: {} seconds'.format(time_elapsed.total_seconds()))\n",
        "\n",
        "  return estimator\n",
        "\n",
        "\n",
        "def train_and_export_model(train_data, train_labels):\n",
        "  model_dir = os.path.join(MODELS_LOCATION, MODEL_NAME)\n",
        "\n",
        "  hparams  = tf.contrib.training.HParams(\n",
        "      batch_size=100,\n",
        "      hidden_units=[1024],\n",
        "      num_conv_layers=2,\n",
        "      init_filters=64,\n",
        "      dropout=0.85,\n",
        "      max_training_steps=50,\n",
        "      eval_throttle_secs=10,\n",
        "      learning_rate=1e-3,\n",
        "      debug=True\n",
        "  )\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      tf_random_seed=19830610,\n",
        "      save_checkpoints_steps=1000,\n",
        "      keep_checkpoint_max=3,\n",
        "      model_dir=model_dir\n",
        "  )\n",
        "\n",
        "  if tf.gfile.Exists(model_dir):\n",
        "      print('Removing previous artifacts...')\n",
        "      tf.gfile.DeleteRecursively(model_dir)\n",
        "\n",
        "  os.makedirs(model_dir)\n",
        "\n",
        "  estimator = run_experiment(hparams, train_data, train_labels, run_config, create_estimator_keras)\n",
        "\n",
        "  def make_serving_input_receiver_fn():\n",
        "      inputs = {'input_image': tf.placeholder(\n",
        "          shape=[None,28,28], dtype=tf.float32, name='serving_input_image')}\n",
        "      return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)\n",
        "\n",
        "  export_dir = os.path.join(model_dir, 'export')\n",
        "\n",
        "  if tf.gfile.Exists(export_dir):\n",
        "      tf.gfile.DeleteRecursively(export_dir)\n",
        "\n",
        "  estimator.export_savedmodel(\n",
        "      export_dir_base=export_dir,\n",
        "      serving_input_receiver_fn=make_serving_input_receiver_fn()\n",
        "  )\n",
        "\n",
        "  return export_dir"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGGMLwruaths"
      },
      "source": [
        "**Train and generate `SavedModel` in `models` folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVdnTarbaWRk",
        "outputId": "83dffc39-1577-4f1b-9be5-7242ebce5197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data, train_labels, eval_data, eval_labels = load_mnist_keras()\n",
        "export_dir = train_and_export_model(train_data.astype('float32'), train_labels.astype('float32'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Experiment started at 06:17:29\n",
            ".......................................\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_image (InputLayer)     [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,509,066\n",
            "Trainable params: 6,508,682\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'models/mnist/keras_classifier', '_tf_random_seed': 19830610, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f52f69c89e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='models/mnist/keras_classifier/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: models/mnist/keras_classifier/keras/keras_model.ckpt\n",
            "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
            "INFO:tensorflow:Warm-started 12 variables.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into models/mnist/keras_classifier/model.ckpt.\n",
            "INFO:tensorflow:loss = 5.7919374, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 50 into models/mnist/keras_classifier/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-10-08T06:17:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-10-08-06:18:55\n",
            "INFO:tensorflow:Saving dict for global step 50: acc = 0.85855, global_step = 50, loss = 0.6727281\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Loss for final step: 0.49285394.\n",
            ".......................................\n",
            "Experiment finished at 06:18:55\n",
            "\n",
            "Experiment elapsed time: 86.073518 seconds\n",
            "WARNING:tensorflow:From <ipython-input-4-3528078d3491>:88: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function has been renamed, use `export_saved_model` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: models/mnist/keras_classifier/export/temp-b'1602137935'/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cotGXyMuaz3b",
        "outputId": "845c63d7-b54c-46a1-c79f-687815b01b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!tree models "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models\n",
            "└── mnist\n",
            "    └── keras_classifier\n",
            "        ├── checkpoint\n",
            "        ├── eval\n",
            "        │   └── events.out.tfevents.1602137935.7114768df0c4\n",
            "        ├── events.out.tfevents.1602137851.7114768df0c4\n",
            "        ├── export\n",
            "        │   └── 1602137935\n",
            "        │       ├── saved_model.pb\n",
            "        │       └── variables\n",
            "        │           ├── variables.data-00000-of-00001\n",
            "        │           └── variables.index\n",
            "        ├── graph.pbtxt\n",
            "        ├── keras\n",
            "        │   ├── checkpoint\n",
            "        │   ├── keras_model.ckpt.data-00000-of-00001\n",
            "        │   ├── keras_model.ckpt.index\n",
            "        │   └── keras_model.ckpt.meta\n",
            "        ├── model.ckpt-0.data-00000-of-00001\n",
            "        ├── model.ckpt-0.index\n",
            "        ├── model.ckpt-0.meta\n",
            "        ├── model.ckpt-50.data-00000-of-00001\n",
            "        ├── model.ckpt-50.index\n",
            "        └── model.ckpt-50.meta\n",
            "\n",
            "7 directories, 17 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uupx7udesHpa",
        "outputId": "bf90861c-4211-42b7-ab0c-d18c49d06d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EXPORT_DIR = '/content/models/mnist/keras_classifier/export'\n",
        "\n",
        "SAVED_MODEL_DIR = os.path.join(\n",
        "    EXPORT_DIR, \n",
        "    [f for f in os.listdir(export_dir) if f.isdigit()][0]\n",
        ")\n",
        "print(SAVED_MODEL_DIR)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/mnist/keras_classifier/export/1602137935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd7DDEtlF-2"
      },
      "source": [
        "# Visualize in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe_RmwyufEv4"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir models/mnist/keras_classifier\n",
        "# click on \"GRAPHS\" on top section"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMJauOQKjCep"
      },
      "source": [
        "# TF Graph Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79dRCB1hZoC",
        "outputId": "468bd45d-6930-4eeb-d7e6-2bae20a795d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "os.environ['DIR'] = SAVED_MODEL_DIR\n",
        "!saved_model_cli show --dir ${DIR} --all"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_image'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28)\n",
            "        name: serving_input_image:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: softmax/Softmax:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvrZqIy3kA_x"
      },
      "source": [
        "def get_graph_def_from_saved_model(saved_model_dir): \n",
        "  with tf.Session() as session:\n",
        "    meta_graph_def = tf.saved_model.loader.load(\n",
        "    session,\n",
        "    tags=[tag_constants.SERVING],\n",
        "    export_dir=saved_model_dir\n",
        "  ) \n",
        "  return meta_graph_def.graph_def"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9b8hB1XkS6R"
      },
      "source": [
        "def describe_graph(graph_def, show_nodes=False):\n",
        "  print('Input Feature Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if node.op=='Placeholder']))\n",
        "  print('')\n",
        "  print('Unused Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if 'unused'  in node.name]))\n",
        "  print('')\n",
        "  print('Output Nodes: {}'.format( \n",
        "      [node.name for node in graph_def.node if (\n",
        "          'predictions' in node.name or 'softmax' in node.name)]))\n",
        "  print('')\n",
        "  print('Quantization Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if 'quant' in node.name]))\n",
        "  print('')\n",
        "  print('Constant Count: {}'.format(\n",
        "      len([node for node in graph_def.node if node.op=='Const'])))\n",
        "  print('')\n",
        "  print('Variable Count: {}'.format(\n",
        "      len([node for node in graph_def.node if 'Variable' in node.op])))\n",
        "  print('')\n",
        "  print('Identity Count: {}'.format(\n",
        "      len([node for node in graph_def.node if node.op=='Identity'])))\n",
        "  print('')\n",
        "  print('Total nodes: {}'.format(len(graph_def.node)), '')\n",
        "\n",
        "  if show_nodes==True:\n",
        "    for node in graph_def.node:\n",
        "      print('Op:{} - Name: {}'.format(node.op, node.name))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuLCaoO-klcR"
      },
      "source": [
        "**Graph Before Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKsuBJqXkXcg",
        "outputId": "aef1c2fe-7fd9-44ad-f0f2-944b01fad31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "describe_graph(get_graph_def_from_saved_model(SAVED_MODEL_DIR))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-93a38003bc15>:6: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /content/models/mnist/keras_classifier/export/1602137935/variables/variables\n",
            "Input Feature Nodes: ['serving_input_image']\n",
            "\n",
            "Unused Nodes: []\n",
            "\n",
            "Output Nodes: ['softmax/Softmax']\n",
            "\n",
            "Quantization Nodes: []\n",
            "\n",
            "Constant Count: 48\n",
            "\n",
            "Variable Count: 65\n",
            "\n",
            "Identity Count: 20\n",
            "\n",
            "Total nodes: 223 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ms9MMA2lmdP"
      },
      "source": [
        "# show nodes (as in tensorboard)\n",
        "# describe_graph(get_graph_def_from_saved_model('/content/models/mnist/keras_classifier/export/1602114568'), True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcPkcGM3mBOJ"
      },
      "source": [
        "**Size of model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRLahuulpAW"
      },
      "source": [
        "def get_size(model_dir, model_file='saved_model.pb'):\n",
        "  \"\"\"\n",
        "   SavedModel size can be roughly summed as \n",
        "   size of the GraphDef and the size of the Variables \n",
        "   (i.e. the weights of the model)\n",
        "   \"\"\"\n",
        "  model_file_path = os.path.join(model_dir, model_file)\n",
        "  print(model_file_path, '')\n",
        "  pb_size = os.path.getsize(model_file_path)\n",
        "  variables_size = 0\n",
        "  if os.path.exists(\n",
        "      os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
        "    variables_size = os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.data-00000-of-00001'))\n",
        "    variables_size += os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.index'))\n",
        "  print('Model size\\t: {} KB'.format(round(pb_size/(1024.0),3)))\n",
        "  print('Variables size\\t: {} KB'.format(round( variables_size/(1024.0),3)))\n",
        "  print('Total Size\\t: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5q9lH1UmEZA",
        "outputId": "82f3e4f9-1d00-48bc-8c2f-ed8d9e0928e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "get_size(SAVED_MODEL_DIR)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/mnist/keras_classifier/export/1602137935/saved_model.pb \n",
            "Model size\t: 40.51 KB\n",
            "Variables size\t: 25426.71 KB\n",
            "Total Size\t: 25467.22 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWwX9Uj_oICP"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr8sV-RgoCJg"
      },
      "source": [
        "def inference_test(saved_model_dir, signature=\"serving_default\", input_name='input_image', batch=300, repeat=100):\n",
        "\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    \n",
        "    time_start = datetime.utcnow() \n",
        "    predictor = tf.contrib.predictor.from_saved_model(\n",
        "        export_dir        = saved_model_dir,\n",
        "        signature_def_key = signature\n",
        "    )\n",
        "    time_end = datetime.utcnow()     \n",
        "    time_elapsed = time_end - time_start\n",
        "   \n",
        "    print(f\"Model loading time : {time_elapsed.total_seconds()} seconds\")\n",
        "    \n",
        "    time_start = datetime.utcnow() \n",
        "    output = None\n",
        "    for i in range(repeat):\n",
        "        predictions = predictor({\n",
        "                input_name: eval_data[:batch]\n",
        "        })\n",
        "        output=[np.argmax(prediction) for prediction in predictions['softmax']]\n",
        "    time_end = datetime.utcnow() \n",
        "    time_elapsed_sec = (time_end - time_start).total_seconds()\n",
        "    \n",
        "    print(f\"\\nPrediction produced for {len(output)} instances batch, repeated {repeat} times\\n\")\n",
        "    print(f\"Inference elapsed time\\t\\t: {time_elapsed_sec} seconds\")\n",
        "    print(f\"Average latency per batch\\t: {time_elapsed_sec/repeat} seconds\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ia455ZDmlBS",
        "outputId": "bd2d9aa7-d9cf-415e-c0d2-26de80603a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "inference_test(SAVED_MODEL_DIR)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loading time : 0.083352 seconds\n",
            "\n",
            "Prediction produced for 300 instances batch, repeated 100 times\n",
            "\n",
            "Inference elapsed time\t\t: 29.558926 seconds\n",
            "Average latency per batch\t: 0.29558926 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKfo-h-orqKH"
      },
      "source": [
        "# Freeze Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ0_i2RwqqkI"
      },
      "source": [
        "def freeze_graph(saved_model_dir):\n",
        "    \n",
        "    from tensorflow.python.tools import freeze_graph\n",
        "    from tensorflow.python.saved_model import tag_constants\n",
        "    \n",
        "    output_graph_filename = os.path.join(saved_model_dir, \"freezed_model.pb\")\n",
        "    output_node_names = \"softmax/Softmax\"\n",
        "    initializer_nodes = \"\"\n",
        "\n",
        "    freeze_graph.freeze_graph(\n",
        "        input_saved_model_dir=saved_model_dir,\n",
        "        output_graph=output_graph_filename,\n",
        "        saved_model_tags = tag_constants.SERVING,\n",
        "        output_node_names=output_node_names,\n",
        "        initializer_nodes=initializer_nodes,\n",
        "\n",
        "        input_graph=None, \n",
        "        input_saver=False,\n",
        "        input_binary=False, \n",
        "        input_checkpoint=None, \n",
        "        restore_op_name=None, \n",
        "        filename_tensor_name=None, \n",
        "        clear_devices=False,\n",
        "        input_meta_graph=False,\n",
        "    )\n",
        "    \n",
        "    print(\"SUCCESS:SavedModel graph freezed!\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb4jBkMwruUQ",
        "outputId": "0156789e-bb6f-4449-8f28-43f6c05e05e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "freeze_graph(SAVED_MODEL_DIR)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS:SavedModel graph freezed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voyLaTybtuOF"
      },
      "source": [
        "# Optimize Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N78ULo77ugAl"
      },
      "source": [
        "def get_graph_def_from_file(graph_filepath):\n",
        "    from tensorflow.python import ops\n",
        "    with ops.Graph().as_default():\n",
        "        with tf.gfile.GFile(graph_filepath, \"rb\") as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            return graph_def"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyDR5yeytB70"
      },
      "source": [
        "def optimize_graph(model_dir, graph_filename, transforms):\n",
        "    \n",
        "    from tensorflow.tools.graph_transforms import TransformGraph\n",
        "    \n",
        "    input_names = []\n",
        "    output_names = ['softmax/Softmax']\n",
        "    \n",
        "    graph_def = get_graph_def_from_file(os.path.join(model_dir, graph_filename))\n",
        "    optimised_graph_def = TransformGraph( graph_def, input_names, \n",
        "                                         output_names, transforms )\n",
        "    # save\n",
        "    tf.train.write_graph(\n",
        "        optimised_graph_def,\n",
        "        logdir=model_dir,\n",
        "        as_text=False,\n",
        "        name='optimised_model.pb'\n",
        "    )\n",
        "    \n",
        "    print(\"SUCCESS:Freezed graph optimised! saved as `optimised_model.pb`\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N8CczFvt4Lo",
        "outputId": "b5dbd1e9-d1c2-44c3-c2aa-9fc4e27458cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transforms = [\n",
        "    'remove_nodes(op=Identity)', \n",
        "    'fold_constants(ignore_errors=true)',\n",
        "    'fold_batch_norms',\n",
        "    #'fuse_resize_pad_and_conv',\n",
        "    #'quantize_weights',\n",
        "    #'quantize_nodes',\n",
        "    'merge_duplicate_nodes',\n",
        "    'strip_unused_nodes', \n",
        "    'sort_by_execution_order'\n",
        "]\n",
        "\n",
        "optimize_graph(SAVED_MODEL_DIR, 'freezed_model.pb', transforms)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS:Freezed graph optimised! saved as `optimised_model.pb`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ogeR_WYvtmo"
      },
      "source": [
        "**Describe optimized graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOsHJYY5uJrZ",
        "outputId": "381b8536-3f27-45a0-8023-0b32599dc5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "describe_graph(get_graph_def_from_file(SAVED_MODEL_DIR + \"/optimised_model.pb\"))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Feature Nodes: ['serving_input_image']\n",
            "\n",
            "Unused Nodes: []\n",
            "\n",
            "Output Nodes: ['softmax/Softmax']\n",
            "\n",
            "Quantization Nodes: []\n",
            "\n",
            "Constant Count: 21\n",
            "\n",
            "Variable Count: 0\n",
            "\n",
            "Identity Count: 0\n",
            "\n",
            "Total nodes: 46 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y-ZuxAWv0Bx"
      },
      "source": [
        "# Note: Total Nodes"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAMiEy1RyxOa"
      },
      "source": [
        "# Unfreeze GraphDef model to SavedModels format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpS9hdS1wOeJ"
      },
      "source": [
        "def convert_graph_def_to_saved_model(graph_filepath):\n",
        "\n",
        "    from tensorflow.python import ops\n",
        "    export_dir=os.path.join(SAVED_MODEL_DIR,'optimised')\n",
        "\n",
        "    if tf.gfile.Exists(export_dir):\n",
        "        tf.gfile.DeleteRecursively(export_dir)\n",
        "\n",
        "    graph_def = get_graph_def_from_file(graph_filepath)\n",
        "    \n",
        "    with tf.Session(graph=tf.Graph()) as session:\n",
        "        tf.import_graph_def(graph_def, name=\"\")\n",
        "        tf.saved_model.simple_save(session,\n",
        "                export_dir,\n",
        "                inputs={\n",
        "                    node.name: session.graph.get_tensor_by_name(\"{}:0\".format(node.name)) \n",
        "                    for node in graph_def.node if node.op=='Placeholder'},\n",
        "                outputs={\n",
        "                    \"softmax\": session.graph.get_tensor_by_name(\"softmax/Softmax:0\"),\n",
        "                }\n",
        "            )\n",
        "\n",
        "        print(\"SUCCESS:Optimised graph converted to SavedModel!\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opoMPRt5y6nf",
        "outputId": "9cbd04dc-8483-4869-adef-2d8aa70e9bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "OPTIMIZED_MODEL_PATH = SAVED_MODEL_DIR + '/optimised_model.pb'\n",
        "\n",
        "convert_graph_def_to_saved_model(OPTIMIZED_MODEL_PATH)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS:Optimised graph converted to SavedModel!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi8aFNY30JPW"
      },
      "source": [
        "**Optimized model size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXfpWspSzQZf",
        "outputId": "b2be75a4-8aa3-4c1b-84c8-63865ad15f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "get_size(\"/content/models/mnist/keras_classifier/export/1602137935/optimised/\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/mnist/keras_classifier/export/1602137935/optimised/saved_model.pb \n",
            "Model size\t: 25434.507 KB\n",
            "Variables size\t: 0.0 KB\n",
            "Total Size\t: 25434.507 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02-vdhjv0Nc1",
        "outputId": "5e7753d5-367b-4243-8385-65d694361c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "get_size(SAVED_MODEL_DIR) # unoptimized"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/mnist/keras_classifier/export/1602137935/saved_model.pb \n",
            "Model size\t: 40.51 KB\n",
            "Variables size\t: 25426.71 KB\n",
            "Total Size\t: 25467.22 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs1SllXd1EGm"
      },
      "source": [
        "# test inference"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmGX76w4Dxv"
      },
      "source": [
        "# References\n",
        "\n",
        "- [Original notebook (Outdated)](https://github.com/GoogleCloudPlatform/tf-estimator-tutorials/blob/master/00_Miscellaneous/model_optimisation/Tutorial%20-%20TensorFlow%20Model%20Optimisation%20for%20Serving%20-%20MNIST%20with%20Keras.ipynb)\n",
        "- [Google Community Blog](https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf)"
      ]
    }
  ]
}