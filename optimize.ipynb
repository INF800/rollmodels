{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcsvDSXhu4H5407cj7xTSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakesh4real/role-models/blob/main/optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G-uSF0VTSyr"
      },
      "source": [
        "- **Tool:** [TF Graph Transforms python API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms)\n",
        "- **Input:** `SavedModel` [format](https://www.tensorflow.org/guide/saved_model) combines a `GraphDef` with checkpoint files that store weights, **all collected in a folder**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytx5Tp81VOoM"
      },
      "source": [
        "# Steps\n",
        "\n",
        "1. Freeze the `SavedModel` model by converting to `Graphdef` format\n",
        "2. Optimize frozen `GraphDef` mode;\n",
        "3. Unfreeze to `SavedModel` format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDm-Axo-X4f9",
        "outputId": "117eb61b-0482-4c4e-e996-beeece75996b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt install tree\n",
        "!pip install tensorflow==1.15.0 # currently v2 is not supported https://github.com/tensorflow/tensorflow/issues/30746. Temp fix - use 1.15.0\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"{'='*60}\\nCurrently using {tf.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 40.3MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=c8bbd80814ad8faedc8bda1a15af3965eb21c89b62d6d359e9cbac68aba114c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfFOTxy7XJvL"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import data\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python import ops\n",
        "\n",
        "from tensorflow.tools.graph_transforms import TransformGraph # currently, not avl. in v2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWv3P4lLVolT"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "MODELS_LOCATION = 'models/mnist'\n",
        "MODEL_NAME = 'keras_classifier'\n",
        "\n",
        "def load_mnist_keras():\n",
        "  (train_data, train_labels), (eval_data, eval_labels) = tf.keras.datasets.mnist.load_data()\n",
        "  return train_data, train_labels, eval_data, eval_labels\n",
        "\n",
        "def keras_model_fn(params):\n",
        "    \n",
        "  inputs = tf.keras.layers.Input(shape=(28, 28), name='input_image')\n",
        "  input_layer = tf.keras.layers.Reshape(target_shape=(28, 28, 1), name='reshape')(inputs)\n",
        "  \n",
        "  # convolutional layers\n",
        "  conv_inputs = input_layer\n",
        "  for i in range(params.num_conv_layers):      \n",
        "    filters = params.init_filters * (2**i)\n",
        "    conv = tf.keras.layers.Conv2D(kernel_size=3, filters=filters, strides=1, padding='SAME', activation='relu')(conv_inputs)\n",
        "    max_pool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='SAME')(conv)\n",
        "    batch_norm = tf.keras.layers.BatchNormalization()(max_pool)\n",
        "    conv_inputs = batch_norm\n",
        "\n",
        "  flatten = tf.keras.layers.Flatten(name='flatten')(conv_inputs)\n",
        "  \n",
        "  # fully-connected layers\n",
        "  dense_inputs = flatten\n",
        "  for i in range(len(params.hidden_units)):      \n",
        "    dense = tf.keras.layers.Dense(units=params.hidden_units[i], activation='relu')(dense_inputs)\n",
        "    dropout = tf.keras.layers.Dropout(params.dropout)(dense)\n",
        "    dense_inputs = dropout\n",
        "      \n",
        "  # softmax classifier\n",
        "  logits = tf.keras.layers.Dense(units=NUM_CLASSES, name='logits')(dense_inputs)\n",
        "  softmax = tf.keras.layers.Activation('softmax', name='softmax')(logits)\n",
        "\n",
        "  # keras model\n",
        "  model = tf.keras.models.Model(inputs, softmax)\n",
        "  return model\n",
        "\n",
        "\n",
        "def create_estimator_keras(params, run_config):\n",
        "    \n",
        "  keras_model = keras_model_fn(params)\n",
        "  print(keras_model.summary())\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.Adam(lr=params.learning_rate)\n",
        "  keras_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  mnist_classifier = tf.keras.estimator.model_to_estimator(\n",
        "      keras_model=keras_model,\n",
        "      config=run_config\n",
        "  )\n",
        "  \n",
        "  return mnist_classifier"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgLwArQUWQUo"
      },
      "source": [
        "def run_experiment(hparams, train_data, train_labels, run_config, create_estimator_fn=create_estimator_keras):\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "      input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "          x={'input_image': train_data},\n",
        "          y=train_labels,\n",
        "          batch_size=hparams.batch_size,\n",
        "          num_epochs=None,\n",
        "          shuffle=True),\n",
        "      max_steps=hparams.max_training_steps\n",
        "  )\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "      input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "          x={'input_image': train_data},\n",
        "          y=train_labels,\n",
        "          batch_size=hparams.batch_size,\n",
        "          num_epochs=1,\n",
        "          shuffle=False),\n",
        "      steps=None,\n",
        "      throttle_secs=hparams.eval_throttle_secs\n",
        "  )\n",
        "\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  time_start = datetime.utcnow()\n",
        "  print('Experiment started at {}'.format(time_start.strftime('%H:%M:%S')))\n",
        "  print('.......................................')\n",
        "\n",
        "  estimator = create_estimator_fn(hparams, run_config)\n",
        "\n",
        "  tf.estimator.train_and_evaluate(\n",
        "      estimator=estimator,\n",
        "      train_spec=train_spec,\n",
        "      eval_spec=eval_spec\n",
        "  )\n",
        "\n",
        "  time_end = datetime.utcnow()\n",
        "  print('.......................................')\n",
        "  print('Experiment finished at {}'.format(time_end.strftime('%H:%M:%S')))\n",
        "  print('')\n",
        "  time_elapsed = time_end - time_start\n",
        "  print('Experiment elapsed time: {} seconds'.format(time_elapsed.total_seconds()))\n",
        "\n",
        "  return estimator\n",
        "\n",
        "\n",
        "def train_and_export_model(train_data, train_labels):\n",
        "  model_dir = os.path.join(MODELS_LOCATION, MODEL_NAME)\n",
        "\n",
        "  hparams  = tf.contrib.training.HParams(\n",
        "      batch_size=100,\n",
        "      hidden_units=[1024],\n",
        "      num_conv_layers=2,\n",
        "      init_filters=64,\n",
        "      dropout=0.85,\n",
        "      max_training_steps=50,\n",
        "      eval_throttle_secs=10,\n",
        "      learning_rate=1e-3,\n",
        "      debug=True\n",
        "  )\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      tf_random_seed=19830610,\n",
        "      save_checkpoints_steps=1000,\n",
        "      keep_checkpoint_max=3,\n",
        "      model_dir=model_dir\n",
        "  )\n",
        "\n",
        "  if tf.gfile.Exists(model_dir):\n",
        "      print('Removing previous artifacts...')\n",
        "      tf.gfile.DeleteRecursively(model_dir)\n",
        "\n",
        "  os.makedirs(model_dir)\n",
        "\n",
        "  estimator = run_experiment(hparams, train_data, train_labels, run_config, create_estimator_keras)\n",
        "\n",
        "  def make_serving_input_receiver_fn():\n",
        "      inputs = {'input_image': tf.placeholder(\n",
        "          shape=[None,28,28], dtype=tf.float32, name='serving_input_image')}\n",
        "      return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)\n",
        "\n",
        "  export_dir = os.path.join(model_dir, 'export')\n",
        "\n",
        "  if tf.gfile.Exists(export_dir):\n",
        "      tf.gfile.DeleteRecursively(export_dir)\n",
        "\n",
        "  estimator.export_savedmodel(\n",
        "      export_dir_base=export_dir,\n",
        "      serving_input_receiver_fn=make_serving_input_receiver_fn()\n",
        "  )\n",
        "\n",
        "  return export_dir"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGGMLwruaths"
      },
      "source": [
        "**Train and generate `SavedModel` in `models` folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVdnTarbaWRk",
        "outputId": "5c21ac0d-1dbd-4339-c5a6-a42a26fabc00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, train_labels, eval_data, eval_labels = load_mnist_keras()\n",
        "export_dir = train_and_export_model(train_data.astype('float32'), train_labels.astype('float32'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing previous artifacts...\n",
            "Experiment started at 23:48:01\n",
            ".......................................\n",
            "WARNING:tensorflow:Large dropout rate: 0.85 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_image (InputLayer)     [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,509,066\n",
            "Trainable params: 6,508,682\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'models/mnist/keras_classifier', '_tf_random_seed': 19830610, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56d0174be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='models/mnist/keras_classifier/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: models/mnist/keras_classifier/keras/keras_model.ckpt\n",
            "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
            "INFO:tensorflow:Warm-started 12 variables.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into models/mnist/keras_classifier/model.ckpt.\n",
            "INFO:tensorflow:loss = 5.8175397, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 50 into models/mnist/keras_classifier/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-10-07T23:48:25Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-10-07-23:49:28\n",
            "INFO:tensorflow:Saving dict for global step 50: acc = 0.89743334, global_step = 50, loss = 0.55444103\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Loss for final step: 0.5634432.\n",
            ".......................................\n",
            "Experiment finished at 23:49:28\n",
            "\n",
            "Experiment elapsed time: 87.56624 seconds\n",
            "WARNING:tensorflow:From <ipython-input-7-3528078d3491>:88: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function has been renamed, use `export_saved_model` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from models/mnist/keras_classifier/model.ckpt-50\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: models/mnist/keras_classifier/export/temp-b'1602114568'/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cotGXyMuaz3b",
        "outputId": "ef4bce76-45c0-4a9a-e00c-0b33a31c7e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tree models "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (150 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 144617 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "models\n",
            "└── mnist\n",
            "    └── keras_classifier\n",
            "        ├── checkpoint\n",
            "        ├── eval\n",
            "        │   └── events.out.tfevents.1602114568.50b1c267a59b\n",
            "        ├── events.out.tfevents.1602114483.50b1c267a59b\n",
            "        ├── export\n",
            "        │   └── 1602114568\n",
            "        │       ├── saved_model.pb\n",
            "        │       └── variables\n",
            "        │           ├── variables.data-00000-of-00001\n",
            "        │           └── variables.index\n",
            "        ├── graph.pbtxt\n",
            "        ├── keras\n",
            "        │   ├── checkpoint\n",
            "        │   ├── keras_model.ckpt.data-00000-of-00001\n",
            "        │   ├── keras_model.ckpt.index\n",
            "        │   └── keras_model.ckpt.meta\n",
            "        ├── model.ckpt-0.data-00000-of-00001\n",
            "        ├── model.ckpt-0.index\n",
            "        ├── model.ckpt-0.meta\n",
            "        ├── model.ckpt-50.data-00000-of-00001\n",
            "        ├── model.ckpt-50.index\n",
            "        └── model.ckpt-50.meta\n",
            "\n",
            "7 directories, 17 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uupx7udesHpa"
      },
      "source": [
        "SAVED_MODEL_DIR = \"/content/models/mnist/keras_classifier/export/1602114568\""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd7DDEtlF-2"
      },
      "source": [
        "# Visualize in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe_RmwyufEv4"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir models/mnist/keras_classifier\n",
        "# click on \"GRAPHS\" on top section"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMJauOQKjCep"
      },
      "source": [
        "# TF Graph Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79dRCB1hZoC",
        "outputId": "825c8030-0657-4137-d59c-46d0a3423be0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!saved_model_cli show --dir /content/models/mnist/keras_classifier/export/1602114568 --all"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_image'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28)\n",
            "        name: serving_input_image:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['softmax'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: softmax/Softmax:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvrZqIy3kA_x"
      },
      "source": [
        "def get_graph_def_from_saved_model(saved_model_dir): \n",
        "  with tf.Session() as session:\n",
        "    meta_graph_def = tf.saved_model.loader.load(\n",
        "    session,\n",
        "    tags=[tag_constants.SERVING],\n",
        "    export_dir=saved_model_dir\n",
        "  ) \n",
        "  return meta_graph_def.graph_def"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9b8hB1XkS6R"
      },
      "source": [
        "def describe_graph(graph_def, show_nodes=False):\n",
        "  print('Input Feature Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if node.op=='Placeholder']))\n",
        "  print('')\n",
        "  print('Unused Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if 'unused'  in node.name]))\n",
        "  print('')\n",
        "  print('Output Nodes: {}'.format( \n",
        "      [node.name for node in graph_def.node if (\n",
        "          'predictions' in node.name or 'softmax' in node.name)]))\n",
        "  print('')\n",
        "  print('Quantization Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.node if 'quant' in node.name]))\n",
        "  print('')\n",
        "  print('Constant Count: {}'.format(\n",
        "      len([node for node in graph_def.node if node.op=='Const'])))\n",
        "  print('')\n",
        "  print('Variable Count: {}'.format(\n",
        "      len([node for node in graph_def.node if 'Variable' in node.op])))\n",
        "  print('')\n",
        "  print('Identity Count: {}'.format(\n",
        "      len([node for node in graph_def.node if node.op=='Identity'])))\n",
        "  print('')\n",
        "  print('Total nodes: {}'.format(len(graph_def.node)), '')\n",
        "\n",
        "  if show_nodes==True:\n",
        "    for node in graph_def.node:\n",
        "      print('Op:{} - Name: {}'.format(node.op, node.name))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuLCaoO-klcR"
      },
      "source": [
        "**Graph Before Optimisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKsuBJqXkXcg",
        "outputId": "9dc783f7-f2c2-4337-a05d-9757957f423b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "describe_graph(get_graph_def_from_saved_model(SAVED_MODEL_DIR))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/models/mnist/keras_classifier/export/1602114568/variables/variables\n",
            "Input Feature Nodes: ['serving_input_image']\n",
            "\n",
            "Unused Nodes: []\n",
            "\n",
            "Output Nodes: ['softmax/Softmax']\n",
            "\n",
            "Quantization Nodes: []\n",
            "\n",
            "Constant Count: 48\n",
            "\n",
            "Variable Count: 65\n",
            "\n",
            "Identity Count: 20\n",
            "\n",
            "Total nodes: 223 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ms9MMA2lmdP"
      },
      "source": [
        "# show nodes (as in tensorboard)\n",
        "# describe_graph(get_graph_def_from_saved_model('/content/models/mnist/keras_classifier/export/1602114568'), True)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcPkcGM3mBOJ"
      },
      "source": [
        "**Size of model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRLahuulpAW"
      },
      "source": [
        "def get_size(model_dir, model_file='saved_model.pb'):\n",
        "  \"\"\"\n",
        "   SavedModel size can be roughly summed as \n",
        "   size of the GraphDef and the size of the Variables \n",
        "   (i.e. the weights of the model)\n",
        "   \"\"\"\n",
        "  model_file_path = os.path.join(model_dir, model_file)\n",
        "  print(model_file_path, '')\n",
        "  pb_size = os.path.getsize(model_file_path)\n",
        "  variables_size = 0\n",
        "  if os.path.exists(\n",
        "      os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
        "    variables_size = os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.data-00000-of-00001'))\n",
        "    variables_size += os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.index'))\n",
        "  print('Model size: {} KB'.format(round(pb_size/(1024.0),3)))\n",
        "  print('Variables size: {} KB'.format(round( variables_size/(1024.0),3)))\n",
        "  print('Total Size: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5q9lH1UmEZA",
        "outputId": "e03b51ac-6f28-4ee2-c4e0-eeed2c62436d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_size(SAVED_MODEL_DIR)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/mnist/keras_classifier/export/1602114568/saved_model.pb \n",
            "Model size: 41.045 KB\n",
            "Variables size: 25426.714 KB\n",
            "Total Size: 25467.759 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWwX9Uj_oICP"
      },
      "source": [
        "#  REST API of TF Serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr8sV-RgoCJg",
        "outputId": "e403b5d6-4cd2-4c66-b36f-35c21ce71f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl -O https://github.com/GoogleCloudPlatform/tf-estimator-tutorials/blob/master/00_Miscellaneous/model_optimisation/tfserving.sh\n",
        "!curl -O https://github.com/GoogleCloudPlatform/tf-estimator-tutorials/blob/master/00_Miscellaneous/model_optimisation/inference_test.py"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 93045    0 93045    0     0   325k      0 --:--:-- --:--:-- --:--:--  325k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k    0  136k    0     0   379k      0 --:--:-- --:--:-- --:--:--  378k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ia455ZDmlBS",
        "outputId": "2399aedf-65c4-48bf-c5a4-fe4c10b4acd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./tfserving.sh # docker required\n",
        "!python inference_test.py tfserving serving_default"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./tfserving.sh: Permission denied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKfo-h-orqKH"
      },
      "source": [
        "# Freeze Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ0_i2RwqqkI"
      },
      "source": [
        "def freeze_graph(saved_model_dir):\n",
        "    \n",
        "    from tensorflow.python.tools import freeze_graph\n",
        "    from tensorflow.python.saved_model import tag_constants\n",
        "    \n",
        "    output_graph_filename = os.path.join(saved_model_dir, \"freezed_model.pb\")\n",
        "    output_node_names = \"softmax/Softmax\"\n",
        "    initializer_nodes = \"\"\n",
        "\n",
        "    freeze_graph.freeze_graph(\n",
        "        input_saved_model_dir=saved_model_dir,\n",
        "        output_graph=output_graph_filename,\n",
        "        saved_model_tags = tag_constants.SERVING,\n",
        "        output_node_names=output_node_names,\n",
        "        initializer_nodes=initializer_nodes,\n",
        "\n",
        "        input_graph=None, \n",
        "        input_saver=False,\n",
        "        input_binary=False, \n",
        "        input_checkpoint=None, \n",
        "        restore_op_name=None, \n",
        "        filename_tensor_name=None, \n",
        "        clear_devices=False,\n",
        "        input_meta_graph=False,\n",
        "    )\n",
        "    \n",
        "    print(\"SUCCESS:SavedModel graph freezed!\")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb4jBkMwruUQ",
        "outputId": "af560fe5-5e53-4085-efef-1560854aeac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "freeze_graph(SAVED_MODEL_DIR)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/models/mnist/keras_classifier/export/1602114568/variables/variables\n",
            "INFO:tensorflow:Froze 16 variables.\n",
            "INFO:tensorflow:Converted 16 variables to const ops.\n",
            "SUCCESS:SavedModel graph freezed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyjd-l4es6FK",
        "outputId": "0768d595-7efe-4515-9d0a-12e142611f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "saved_models_base=models/mnist/keras_classifier/export/\n",
        "saved_model_dir=${saved_models_base}$(ls ${saved_models_base} | tail -n 1)\n",
        "echo ${saved_model_dir}\n",
        "ls ${saved_model_dir}"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models/mnist/keras_classifier/export/1602114568\n",
            "freezed_model.pb\n",
            "saved_model.pb\n",
            "variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voyLaTybtuOF"
      },
      "source": [
        "# Optimize Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N78ULo77ugAl"
      },
      "source": [
        "def get_graph_def_from_file(graph_filepath):\n",
        "    from tensorflow.python import ops\n",
        "    with ops.Graph().as_default():\n",
        "        with tf.gfile.GFile(graph_filepath, \"rb\") as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            return graph_def"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyDR5yeytB70"
      },
      "source": [
        "def optimize_graph(model_dir, graph_filename, transforms):\n",
        "    \n",
        "    from tensorflow.tools.graph_transforms import TransformGraph\n",
        "    \n",
        "    input_names = []\n",
        "    output_names = ['softmax/Softmax']\n",
        "    \n",
        "    graph_def = get_graph_def_from_file(os.path.join(model_dir, graph_filename))\n",
        "    optimised_graph_def = TransformGraph(graph_def, \n",
        "                                         input_names,\n",
        "                                         output_names,\n",
        "                                         transforms \n",
        "                                        )\n",
        "    tf.train.write_graph(optimised_graph_def,\n",
        "                        logdir=model_dir,\n",
        "                        as_text=False,\n",
        "                        name='optimised_model.pb')\n",
        "    \n",
        "    print(\"SUCCESS:Freezed graph optimised!\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N8CczFvt4Lo",
        "outputId": "092f9d2a-9949-4928-cc65-f0385a461879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transforms = [\n",
        "    'remove_nodes(op=Identity)', \n",
        "    'fold_constants(ignore_errors=true)',\n",
        "    'fold_batch_norms',\n",
        "    #'fuse_resize_pad_and_conv',\n",
        "    #'quantize_weights',\n",
        "    #'quantize_nodes',\n",
        "    'merge_duplicate_nodes',\n",
        "    'strip_unused_nodes', \n",
        "    'sort_by_execution_order'\n",
        "]\n",
        "\n",
        "optimize_graph(SAVED_MODEL_DIR, 'freezed_model.pb', transforms)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS:Freezed graph optimised!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOsHJYY5uJrZ"
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    }
  ]
}